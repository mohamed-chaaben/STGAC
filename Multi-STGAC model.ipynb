{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Swt_5dNp8cXFJ7GpdilitFvVhL1FfLVO",
     "timestamp": 1655735957436
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Import the necessary python packages.**"
   ],
   "metadata": {
    "id": "-EzwQwxes4Ai"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JdJzRRICRRPM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057821795,
     "user_tz": 300,
     "elapsed": 2658,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Processing"
   ],
   "metadata": {
    "id": "holHEJXJ8Oqh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import Data**.\n",
    "\n",
    "\n",
    "\n",
    "``` Main matrix ``` with 410 stops, starting from ```2021-09-13 05:00:00``` to ```2021-10-10 23:00:00```.\n",
    "\n",
    "```A``` is the corresponding adjacency matrix, and ```BNP``` is the bus proximity matrix.\n",
    "\n"
   ],
   "metadata": {
    "id": "WFq5k3N67aAo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "kxp_YaHcoDvH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057821796,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "main_df = pd.read_pickle(\"inputs/main_matrix_5_23.pkl\")\n",
    "with open(\"inputs/A_5_23\", 'rb') as f:\n",
    "    A = pickle.load(f)\n",
    "A = torch.tensor(A).to(device)"
   ],
   "metadata": {
    "id": "uRePNzjpYNqT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057825016,
     "user_tz": 300,
     "elapsed": 3223,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bnp_data = pd.read_pickle(\"inputs/frame_of_speed_matrix.pickle\")"
   ],
   "metadata": {
    "id": "nVf5Gfq-oDvH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057844943,
     "user_tz": 300,
     "elapsed": 19939,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data preparation**\n",
    "\n",
    "```ConcatDataset``` class help to consider 3 types of datasets simultaneously (recent, daily-periodic and weekly-periodic data)."
   ],
   "metadata": {
    "id": "zOh9Kip4til5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return tuple(d[i % len(d)] for d in self.datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(d) for d in self.datasets)"
   ],
   "metadata": {
    "id": "zwm0nuCGpsIz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057844944,
     "user_tz": 300,
     "elapsed": 12,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def PrepareDataset(main_passenger_matrix, BATCH_SIZE=20, pred_len=1, train_propotion=0.7, valid_propotion=0.2):\n",
    "    time_len = main_passenger_matrix.shape[0]\n",
    "\n",
    "    max_load = main_passenger_matrix.max().max()\n",
    "    main_passenger_matrix = main_passenger_matrix / max_load\n",
    "    main_passenger_matrix.insert(0,'index',range(1,len(main_passenger_matrix)+1),False)\n",
    "\n",
    "    # Weekly-periodic data preparation\n",
    "    pass_sequences, pass_labels = [], []\n",
    "\n",
    "    # Number of historical sequence\n",
    "    seq_len = 2\n",
    "\n",
    "    for i in range(time_len - 109 * 7 * (seq_len + pred_len)):\n",
    "        pass_sequences.append(main_passenger_matrix.iloc[[i + 109 * 7 * j for j in range(seq_len)]].values)  #109 is the number of steps between two consecutive days\n",
    "        pass_labels.append(main_passenger_matrix.iloc[[i + 109 * 7 * (seq_len + j) for j in range(pred_len)]].values)\n",
    "\n",
    "    pass_sequences, pass_labels = np.asarray(pass_sequences), np.asarray(pass_labels)\n",
    "\n",
    "    sample_size = pass_sequences.shape[0]\n",
    "\n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * (train_propotion + valid_propotion)))\n",
    "\n",
    "    # randomize the order of sequences\n",
    "\n",
    "    c = list(zip(pass_sequences, pass_labels))\n",
    "    random.shuffle(c)\n",
    "    pass_sequences, pass_labels = zip(*c)\n",
    "\n",
    "    train_data, train_label = pass_sequences[:train_index], pass_labels[:train_index]\n",
    "    valid_data, valid_label = pass_sequences[train_index:valid_index], pass_labels[train_index:valid_index]\n",
    "    test_data, test_label = pass_sequences[valid_index:], pass_labels[valid_index:]\n",
    "\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "\n",
    "    train_dataset_w = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset_w = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset_w = utils.TensorDataset(test_data, test_label)\n",
    "    # Daily-periodic data preparation\n",
    "\n",
    "    seq_len = 4\n",
    "    pass_sequences, pass_labels = [], []\n",
    "\n",
    "    # Specify the time range from which to get the data\n",
    "    maind = main_passenger_matrix.loc['2021-09-23 05:00:00':'2021-10-04 23:00:00']\n",
    "\n",
    "    time_len = maind.shape[0]\n",
    "\n",
    "    for i in range(time_len - 109 * (seq_len + pred_len)):\n",
    "        pass_sequences.append(maind.iloc[[i + 109 * j for j in range(seq_len)]].values)\n",
    "        pass_labels.append(maind.iloc[[i + 109 * (seq_len + j) for j in range(pred_len)]].values)\n",
    "\n",
    "    pass_sequences, pass_labels = np.asarray(pass_sequences), np.asarray(pass_labels)\n",
    "\n",
    "    sample_size = pass_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype=int)\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * (train_propotion + valid_propotion)))\n",
    "\n",
    "    # randomize the order of sequences\n",
    "\n",
    "    c = list(zip(pass_sequences, pass_labels))\n",
    "    random.shuffle(c)\n",
    "    pass_sequences, pass_labels = zip(*c)\n",
    "\n",
    "    train_data, train_label = pass_sequences[:train_index], pass_labels[:train_index]\n",
    "    valid_data, valid_label = pass_sequences[train_index:valid_index], pass_labels[train_index:valid_index]\n",
    "    test_data, test_label = pass_sequences[valid_index:], pass_labels[valid_index:]\n",
    "\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "\n",
    "    train_dataset_d = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset_d = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset_d = utils.TensorDataset(test_data, test_label)\n",
    "\n",
    "    # Recent data preparation\n",
    "\n",
    "    seq_len = 10\n",
    "    pass_sequences, pass_labels = [], []\n",
    "\n",
    "    # Specify the time range from which to get the data\n",
    "    mainr = main_passenger_matrix.loc['2021-09-26 21:30:00':'2021-10-04 05:00:00']\n",
    "\n",
    "    time_len = mainr.shape[0]\n",
    "    for i in range(time_len - (seq_len + pred_len)):\n",
    "        pass_sequences.append(mainr.iloc[[i + j for j in range(seq_len)]].values)\n",
    "        pass_labels.append(mainr.iloc[[i + (seq_len + j) for j in range(pred_len)]].values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pass_sequences, pass_labels = np.asarray(pass_sequences), np.asarray(pass_labels)\n",
    "\n",
    "    sample_size = pass_sequences.shape[0]\n",
    "    index = np.arange(sample_size, dtype=int)\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    train_index = int(np.floor(sample_size * train_propotion))\n",
    "    valid_index = int(np.floor(sample_size * (train_propotion + valid_propotion)))\n",
    "\n",
    "    # randomize the order of sequences\n",
    "\n",
    "    c = list(zip(pass_sequences, pass_labels))\n",
    "    random.shuffle(c)\n",
    "    pass_sequences, pass_labels = zip(*c)\n",
    "\n",
    "    train_data, train_label = pass_sequences[:train_index], pass_labels[:train_index]\n",
    "    valid_data, valid_label = pass_sequences[train_index:valid_index], pass_labels[train_index:valid_index]\n",
    "    test_data, test_label = pass_sequences[valid_index:], pass_labels[valid_index:]\n",
    "\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "\n",
    "    train_dataset_r = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset_r = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset_r = utils.TensorDataset(test_data, test_label)\n",
    "\n",
    "    # All the data in one dataloader\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ConcatDataset(train_dataset_r, train_dataset_d, train_dataset_w),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        ConcatDataset(valid_dataset_r, valid_dataset_d, valid_dataset_w),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        ConcatDataset(test_dataset_r, test_dataset_d, test_dataset_w),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, max_load"
   ],
   "metadata": {
    "id": "a7iz6r_2YxqA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057844944,
     "user_tz": 300,
     "elapsed": 12,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6640/236109387.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader, max_load = PrepareDataset(main_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfNeioh_oDvJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847365,
     "user_tz": 300,
     "elapsed": 2432,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    },
    "outputId": "17864b4c-e0d9-4b9a-91b3-622243284893"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Architecture"
   ],
   "metadata": {
    "id": "OnzmmFpilROQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Temporal Gated Dilated Convolution (Temporal-GDCN) Layer "
   ],
   "metadata": {
    "id": "jpVllU2ybefJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GDCN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim=1, blocks=2, layers=2, residual_channels=1, dilation_channels=1, kernel_size=2):\n",
    "        super(GDCN, self).__init__()\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim, out_channels=residual_channels, kernel_size=(1, 1),\n",
    "                                    padding='same')\n",
    "\n",
    "        for b in range(blocks):\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                #dialated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels, out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1, kernel_size), dilation=new_dilation, padding='same'))\n",
    "                self.gate_convs.append(nn.Conv2d(in_channels=residual_channels, out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation, padding='same'))\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = torch.unsqueeze(torch.unsqueeze(input, 0), 0)\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        for i in range(self.blocks * self.layers):\n",
    "            residual = x\n",
    "\n",
    "            # dilated convolution\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "\n",
    "            x = filter * gate\n",
    "\n",
    "        x = torch.squeeze(x, 1)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x = torch.squeeze(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "nQigV27-lNYN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847366,
     "user_tz": 300,
     "elapsed": 21,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Spatial Graph Attention Convolution (Spatial-GACN) Layer\n",
    "\n",
    "\n",
    "*   Graph Attention Network (GAT)\n",
    "*   Graph Concolution Network (GCN)\n",
    "\n"
   ],
   "metadata": {
    "id": "lcAxejtNb5wj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a verifier l'attention ici dans ce cas"
   ],
   "metadata": {
    "id": "JEIggzR1xjum"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_features=200, out_features=200, dropout=0.3):\n",
    "        super(GAT, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)).to(device))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.empty(size=(2 * out_features, 1)).to(device))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        # adj is the adjacency matrix\n",
    "        Wh = torch.matmul(h, self.W)\n",
    "        e = self._prepare_attentional_mechanism_input(Wh)\n",
    "\n",
    "        zero_vec = -9e15 * torch.ones_like(e)\n",
    "        #attention = torch.where(adj > 0, e, zero_vec)\n",
    "        attention = adj\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime = torch.matmul(attention.float(), Wh)\n",
    "        return F.elu(h_prime)\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, Wh):\n",
    "        Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])\n",
    "        Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])\n",
    "\n",
    "        # broadcast add\n",
    "        e = Wh1 + Wh2.T\n",
    "        return self.leakyrelu(e)\n"
   ],
   "metadata": {
    "id": "P0g15CpjlLJx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847366,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    #         print(self.weight.data)\n",
    "    #         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.filter_square_matrix.matmul(self.weight.double()), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ],
   "metadata": {
    "id": "2swqf0WplJKP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847366,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, A, feature_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.A = A\n",
    "        self.linear = FilterLinear(410, 410, self.A, bias=False)\n",
    "\n",
    "    def forward(self, input, BNP):\n",
    "        #some squeeze and unsqueeze\n",
    "        x = torch.einsum('ij,xyij -> xyij', self.A, torch.Tensor(BNP).double())\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(-1,410,410)\n",
    "        x = torch.einsum('ij,ijk->ik', input.double().transpose(0,1), x.double())\n",
    "        return x.transpose(0,1)"
   ],
   "metadata": {
    "id": "JbNfIVsGfs08",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847366,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "TSM Modules\n",
    "\n",
    "```TSM_first``` for the first TSM module and ```TSM_others``` for the remaining modules."
   ],
   "metadata": {
    "id": "QjCrllAUfVko"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class TSM_first(nn.Module):\n",
    "    def __init__(self, A, in_features=200, out_features=200):\n",
    "        super(TSM_first, self).__init__()\n",
    "        self.GDCN1 = GDCN()\n",
    "        self.GDCN2 = GDCN()\n",
    "        self.gat = GAT(in_features=in_features, out_features=out_features)\n",
    "        self.A = A\n",
    "        self.GCN1 = GCN(A, in_features)\n",
    "        self.GCN2 = GCN(A, in_features)\n",
    "        self.BN1 = nn.BatchNorm1d(in_features)\n",
    "        self.BN2 = nn.BatchNorm1d(in_features)\n",
    "\n",
    "        self.nodevec1 = nn.Parameter(torch.randn(int(A.shape[0]), 10).to(device), requires_grad=True).to(device)\n",
    "        self.nodevec2 = nn.Parameter(torch.randn(10, int(A.shape[0])).to(device), requires_grad=True).to(device)\n",
    "\n",
    "        self.nodevec3 = nn.Parameter(torch.randn(int(A.shape[0]), 10).to(device), requires_grad=True).to(device)\n",
    "        self.nodevec4 = nn.Parameter(torch.randn(10, int(A.shape[0])).to(device), requires_grad=True).to(device)\n",
    "\n",
    "    def forward(self, input, BNP):\n",
    "        BNP = torch.squeeze(BNP)\n",
    "        x = input.reshape((input.shape[0] * input.shape[1]), input.shape[2])\n",
    "        x1 = self.GDCN1(x)\n",
    "        x_middle = self.gat(x1, self.A)\n",
    "        x_middle = self.GCN1(x_middle, BNP)\n",
    "        x = self.BN1(x.permute(1, 0) + x_middle.float()).permute(1, 0)\n",
    "\n",
    "        x2 = self.GDCN2(x)\n",
    "        x_middle = self.gat(x2, self.A)\n",
    "        x_middle = self.GCN2(x_middle, BNP)\n",
    "        x = self.BN2(x.permute(1, 0) + x_middle.float()).permute(1, 0)\n",
    "\n",
    "        return x, x1, x2"
   ],
   "metadata": {
    "id": "E9GPeIW6lGvK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847367,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TSM_others(nn.Module):\n",
    "    def __init__(self, A, in_features=200, out_features=200):\n",
    "        super(TSM_others, self).__init__()\n",
    "        self.GDCN1 = GDCN()\n",
    "        self.GDCN2 = GDCN()\n",
    "        self.gat = GAT(in_features=in_features, out_features=out_features)\n",
    "        self.A = A\n",
    "        self.GCN1 = GCN(A, in_features)\n",
    "        self.GCN2 = GCN(A, in_features)\n",
    "        self.BN1 = nn.BatchNorm1d(in_features)\n",
    "        self.BN2 = nn.BatchNorm1d(in_features)\n",
    "\n",
    "        self.nodevec1 = nn.Parameter(torch.randn(int(A.shape[0]), 10).to(device), requires_grad=True).to(device)\n",
    "        self.nodevec2 = nn.Parameter(torch.randn(10, int(A.shape[0])).to(device), requires_grad=True).to(device)\n",
    "\n",
    "        self.nodevec3 = nn.Parameter(torch.randn(int(A.shape[0]), 10).to(device), requires_grad=True).to(device)\n",
    "        self.nodevec4 = nn.Parameter(torch.randn(10, int(A.shape[0])).to(device), requires_grad=True).to(device)\n",
    "\n",
    "    def forward(self, x, BNP):\n",
    "        BNP = torch.squeeze(BNP)\n",
    "        x1 = self.GDCN1(x)\n",
    "        x_middle = self.gat(x1, self.A)\n",
    "        x_middle = self.GCN1(x_middle, BNP)\n",
    "        x = self.BN1(x.permute(1, 0) + x_middle.float()).permute(1, 0)\n",
    "\n",
    "        x2 = self.GDCN2(x)\n",
    "        x_middle = self.gat(x2, self.A)\n",
    "        x_middle = self.GCN2(x_middle, BNP)\n",
    "        x = self.BN2(x.permute(1, 0) + x_middle.float()).permute(1, 0)\n",
    "\n",
    "        return x, x1, x2"
   ],
   "metadata": {
    "id": "vsNs8N6jlDu9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847367,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class linear(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(1, 1), padding=(0, 0), stride=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ],
   "metadata": {
    "id": "g3Vz8K9usQ_1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847367,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A component contains the 4 TSM modules, for each type of data"
   ],
   "metadata": {
    "id": "dhPQ7A7xkMZU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class COMPONENT(nn.Module):\n",
    "    def __init__(self, A, inp=200, out=200):\n",
    "        super(COMPONENT, self).__init__()\n",
    "        self.A = A\n",
    "        self.TSM1 = TSM_first(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
    "        self.TSM2 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
    "        self.TSM3 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
    "        self.TSM4 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
    "        self.RL = nn.ReLU()\n",
    "        self.conv1 = linear(1, 1)\n",
    "        self.conv2 = linear(1, 1)\n",
    "        self.linear = nn.Linear(inp, out_features=20)\n",
    "\n",
    "    def forward(self, x, BNP):\n",
    "        x, x11, x12 = self.TSM1(x, BNP)\n",
    "        x, x21, x22 = self.TSM2(x, BNP)\n",
    "        x, x31, x32 = self.TSM3(x, BNP)\n",
    "        x, x41, x42 = self.TSM4(x, BNP)\n",
    "\n",
    "        x = self.RL(x11 + x12 + x21 + x22 + x31 + x32 + x41 + x42)\n",
    "        x = torch.unsqueeze(torch.unsqueeze(x, 0), 0)\n",
    "        x = self.conv1(x)\n",
    "        x = self.RL(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.RL(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.linear(x)\n",
    "        return x.permute(1, 0)"
   ],
   "metadata": {
    "id": "pCcwr8e6lA3C",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847367,
     "user_tz": 300,
     "elapsed": 19,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main model"
   ],
   "metadata": {
    "id": "3cDcunJKlbMp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Multi_STGAC(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        super(Multi_STGAC, self).__init__()\n",
    "        self.A = A\n",
    "        self.Recent_component = COMPONENT(A, 20 * 10, 20 * 10)  # 20 is the batch size and 10 is the sequence length\n",
    "        self.Daily_component = COMPONENT(A, 20 * 4, 20 * 4)\n",
    "        self.Weekly_component = COMPONENT(A, 20 * 2, 20 * 2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3 * 410, out_channels=410, kernel_size=1, padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels=410, out_channels=410, kernel_size=(1, 1), padding='same')\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, Xr, Xd, Xw, BNPr, BNPd,BNPw):\n",
    "        X1 = self.Recent_component(Xr,BNPr)\n",
    "        X2 = self.Daily_component(Xd,BNPd)\n",
    "        X3 = self.Weekly_component(Xw,BNPw)\n",
    "        #Concatenation operation\n",
    "        Y = torch.cat((X1, X2, X3), 1)\n",
    "        Y = torch.unsqueeze(torch.unsqueeze(Y, 2), 3)\n",
    "        Y = self.conv1(Y)\n",
    "        Y = self.elu(Y)\n",
    "        Y = self.conv2(Y)\n",
    "        Y = torch.squeeze(Y)\n",
    "        return Y"
   ],
   "metadata": {
    "id": "aAw2q15rYzn2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847368,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "```\n",
    "train_loader.dataset =  (timestep, (recent data, daily-periodic, weekly-periodic data), (historical data, nextstep data) )\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "rX3533hFJM7w"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model function"
   ],
   "metadata": {
    "id": "mbepgjAgQyBd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def create_BNP(inputs_R):\n",
    "    Tindex = inputs_R[:,:,0:1]\n",
    "    output0 = torch.empty(1,inputs_R.shape[1],410,410)\n",
    "    for i in range(inputs_R.shape[0]-1):\n",
    "        output1 = torch.empty(1,1,410,410)\n",
    "        for j in range(inputs_R.shape[1]-1):\n",
    "            output1 = torch.cat((output1,torch.tensor(bnp_data.iloc[int(Tindex[i,j,0]),0][0]).unsqueeze(0).unsqueeze(0)), dim=1)\n",
    "        output0 = torch.cat((output0, output1), dim=0)\n",
    "    return output0"
   ],
   "metadata": {
    "id": "PbkKusLSoDvM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847368,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate=1e-5, num_epochs=300, patience=10, min_delta=0.00001):\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    model.to(device)\n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "\n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('New epoch started')\n",
    "        trained_number = 0\n",
    "\n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "\n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "        for data in train_dataloader:\n",
    "            print('Start a new batch import')\n",
    "            inputs_R, labels_R = data[0]\n",
    "            inputs_D, labels_D = data[1]\n",
    "            inputs_W, labels_W = data[2]\n",
    "\n",
    "            BNP_R, BNP_D, BNP_W = create_BNP(inputs_R), create_BNP(inputs_D), create_BNP(inputs_W)\n",
    "            BNP_R, BNP_D, BNP_W = Variable(BNP_R), Variable(BNP_D), Variable(BNP_W)\n",
    "\n",
    "\n",
    "            inputs_R, labels_R = Variable(inputs_R[:,:,1:]), Variable(labels_R[:,:,1:])\n",
    "            inputs_D, labels_D = Variable(inputs_D[:,:,1:]), Variable(labels_D[:,:,1:])\n",
    "            inputs_W, labels_W = Variable(inputs_W[:,:,1:]), Variable(labels_W[:,:,1:])\n",
    "\n",
    "            inputs_R = inputs_R.to(device)\n",
    "            inputs_D = inputs_D.to(device)\n",
    "            inputs_W = inputs_W.to(device)\n",
    "            BNP_R = BNP_R.to(device)\n",
    "            BNP_D = BNP_D.to(device)\n",
    "            BNP_W = BNP_W.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs_R, inputs_D, inputs_W, BNP_R, BNP_D, BNP_W)\n",
    "            del inputs_R\n",
    "            del inputs_D\n",
    "            del inputs_W\n",
    "            del BNP_R\n",
    "            del BNP_D\n",
    "            del BNP_W\n",
    "            print(\"Outputs from model Done\")\n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels_R).to(device))\n",
    "\n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            print(\"Start Validation\")\n",
    "            # validation\n",
    "            try:\n",
    "                data_val = next(valid_dataloader_iter)\n",
    "                inputs_val_R, labels_val_R = data_val[0]\n",
    "                inputs_val_D, labels_val_D = data_val[1]\n",
    "                inputs_val_W, labels_val_W = data_val[2]\n",
    "                \n",
    "            \n",
    "                BNP_val_R, BNP_val_D, BNP_val_W = create_BNP(inputs_val_R), create_BNP(inputs_val_D), create_BNP(inputs_val_W)\n",
    "                BNP_val_R, BNP_val_D, BNP_val_W = Variable(BNP_val_R), Variable(BNP_val_D), Variable(BNP_val_W)\n",
    "\n",
    "                inputs_val_R, labels_val_R = Variable(inputs_val_R[:,:,1:]), Variable(labels_val_R[:,:,1:])\n",
    "                inputs_val_D, labels_val_D = Variable(inputs_val_D[:,:,1:]), Variable(labels_val_D[:,:,1:])\n",
    "                inputs_val_W, labels_val_W = Variable(inputs_val_W[:,:,1:]), Variable(labels_val_W[:,:,1:])\n",
    "\n",
    "                inputs_val_R = inputs_val_R.to(device)\n",
    "                inputs_val_D = inputs_val_D.to(device)\n",
    "                inputs_val_W = inputs_val_W.to(device)\n",
    "                BNP_val_R = BNP_val_R.to(device)\n",
    "                BNP_val_D = BNP_val_D.to(device)\n",
    "                BNP_val_W = BNP_val_W.to(device)\n",
    "                outputs_val = model(inputs_val_R, inputs_val_D, inputs_val_W, BNP_val_R, BNP_val_D, BNP_val_W)\n",
    "\n",
    "                del inputs_val_R\n",
    "                del inputs_val_D\n",
    "                del inputs_val_W\n",
    "                del BNP_val_W\n",
    "                del BNP_val_D\n",
    "                del BNP_val_R\n",
    "\n",
    "            except StopIteration:\n",
    "                print(\"STOP ITERATION\")\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                data_val = next(valid_dataloader_iter)\n",
    "\n",
    "            print(\"Outputs of Validation Done\")\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val_R).to(device))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "\n",
    "            # output\n",
    "            trained_number += 1\n",
    "\n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "\n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "\n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, val_loss:{} ,time: {}, best model: {}'.format(\n",
    "            epoch,\n",
    "            torch.round(torch.tensor(avg_losses_epoch_train), decimals=8),\n",
    "            torch.round(torch.tensor(avg_losses_epoch_valid), decimals=8),\n",
    "            torch.round(torch.tensor([cur_time - pre_time]), decimals=2),\n",
    "            is_best_model))\n",
    "        pre_time = cur_time\n",
    "\n",
    "    return model, [losses_train, losses_epochs_train, losses_epoch_valid], is_best_model"
   ],
   "metadata": {
    "id": "MQOyJrFOoDvN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847368,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Execute and test model"
   ],
   "metadata": {
    "id": "7bblF4JZQ3R-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Multi_STGAC(A)"
   ],
   "metadata": {
    "id": "sZudzI6TymcO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba0c408a-0e38-4566-e16f-b5e8d13a8893",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676057847368,
     "user_tz": 300,
     "elapsed": 20,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6640/1274560894.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.TSM1 = TSM_first(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
      "/tmp/ipykernel_6640/1274560894.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.TSM2 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
      "/tmp/ipykernel_6640/1274560894.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.TSM3 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n",
      "/tmp/ipykernel_6640/1274560894.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.TSM4 = TSM_others(A=torch.tensor(self.A), in_features=inp, out_features=out)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model, [losses_train, losses_epochs_train, losses_epoch_valid], is_best_model = TrainModel(model, train_loader, valid_loader)"
   ],
   "metadata": {
    "id": "P82BMBZtoAaC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1676058137156,
     "user_tz": 300,
     "elapsed": 289804,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    },
    "outputId": "27258918-ecba-448b-99fa-6c40acd18ead"
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6640/847523977.py:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.round(torch.tensor(avg_losses_epoch_train), decimals=8),\n",
      "/tmp/ipykernel_6640/847523977.py:145: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.round(torch.tensor(avg_losses_epoch_valid), decimals=8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: nan, val_loss:nan ,time: tensor([82.7100]), best model: 1\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 1, train_loss: nan, val_loss:nan ,time: tensor([83.0500]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 2, train_loss: nan, val_loss:nan ,time: tensor([83.3500]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 3, train_loss: nan, val_loss:nan ,time: tensor([84.1200]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 4, train_loss: nan, val_loss:nan ,time: tensor([83.2900]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 5, train_loss: nan, val_loss:nan ,time: tensor([83.2900]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Epoch: 6, train_loss: nan, val_loss:nan ,time: tensor([83.6100]), best model: 0\n",
      "New epoch started\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "STOP ITERATION\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n",
      "Outputs of Validation Done\n",
      "Start a new batch import\n",
      "Outputs from model Done\n",
      "Start Validation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model, [losses_train, losses_epochs_train, losses_epoch_valid], is_best_model \u001B[38;5;241m=\u001B[39m \u001B[43mTrainModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[31], line 80\u001B[0m, in \u001B[0;36mTrainModel\u001B[0;34m(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, patience, min_delta)\u001B[0m\n\u001B[1;32m     76\u001B[0m inputs_val_D, labels_val_D \u001B[38;5;241m=\u001B[39m data_val[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     77\u001B[0m inputs_val_W, labels_val_W \u001B[38;5;241m=\u001B[39m data_val[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m---> 80\u001B[0m BNP_val_R, BNP_val_D, BNP_val_W \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_BNP\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs_val_R\u001B[49m\u001B[43m)\u001B[49m, create_BNP(inputs_val_D), create_BNP(inputs_val_W)\n\u001B[1;32m     81\u001B[0m BNP_val_R, BNP_val_D, BNP_val_W \u001B[38;5;241m=\u001B[39m Variable(BNP_val_R), Variable(BNP_val_D), Variable(BNP_val_W)\n\u001B[1;32m     83\u001B[0m inputs_val_R, labels_val_R \u001B[38;5;241m=\u001B[39m Variable(inputs_val_R[:,:,\u001B[38;5;241m1\u001B[39m:]), Variable(labels_val_R[:,:,\u001B[38;5;241m1\u001B[39m:])\n",
      "Cell \u001B[0;32mIn[30], line 7\u001B[0m, in \u001B[0;36mcreate_BNP\u001B[0;34m(inputs_R)\u001B[0m\n\u001B[1;32m      5\u001B[0m     output1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m410\u001B[39m,\u001B[38;5;241m410\u001B[39m)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(inputs_R\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m----> 7\u001B[0m         output1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((output1,\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbnp_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTindex\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      8\u001B[0m     output0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((output0, output1), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output0\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "G8SvHpE5vQzj",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1676058137158,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rmse(input, target):\n",
    "    #input and target of shape (x,y)\n",
    "    N = target.shape[1]\n",
    "    return np.sqrt(((input - target) ** 2).sum(axis=1) / N)\n",
    "\n",
    "\n",
    "def mae(input, target):\n",
    "    #input and target of shape (x,y)\n",
    "    N = target.shape[1]\n",
    "    return np.abs(input - target).sum(axis=1) / N\n",
    "\n",
    "\n",
    "# for the 4-bin accuracy\n",
    "def ranging(table):\n",
    "    return 1 * (table >= 0) * (table <= 5) + 2 * (table >= 6) * (table <= 10) + 3 * (table >= 11) * (\n",
    "            table <= 15) + 4 * (table >= 16)\n",
    "\n",
    "\n",
    "def bins_accuracy(output, label):\n",
    "    output = ranging(output)\n",
    "    label = ranging(label)\n",
    "    return accuracy_score(output, label)"
   ],
   "metadata": {
    "id": "Y0lnWwl6ztm_",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1676058137158,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def TestModel(model, test_dataloader, max_load):\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    tested_batch = 0\n",
    "\n",
    "    losses_rmse = []\n",
    "    losses_mae = []\n",
    "    acc = []\n",
    "    acc_bin = []\n",
    "\n",
    "    for data in test_dataloader:\n",
    "        inputs_R, labels_R = data[0]\n",
    "        inputs_D, labels_D = data[1]\n",
    "        inputs_W, labels_W = data[2]\n",
    "\n",
    "        inputs_R, labels_R = Variable(inputs_R), Variable(labels_R)\n",
    "        inputs_D, labels_D = Variable(inputs_D), Variable(labels_D)\n",
    "        inputs_W, labels_W = Variable(inputs_W), Variable(labels_W)\n",
    "\n",
    "        outputs = model(inputs_R, inputs_D, inputs_W)\n",
    "\n",
    "        loss_mae = mae(outputs.detach().numpy() * max_load, torch.squeeze(labels_R).detach().numpy() * max_load)\n",
    "        losses_mae.append(loss_mae)\n",
    "\n",
    "        loss_rmse = rmse(outputs.detach().numpy() * max_load, torch.squeeze(labels_R).detach().numpy() * max_load)\n",
    "        losses_rmse.append(loss_rmse)\n",
    "\n",
    "        accuracy = accuracy_score(np.rint(outputs.detach().numpy().flatten() * max_load),\n",
    "                                  np.rint(torch.squeeze(labels_R).detach().numpy().flatten() * max_load))\n",
    "        acc.append(accuracy)\n",
    "\n",
    "        accuracy_bins = bins_accuracy(np.rint(outputs.detach().numpy().flatten() * max_load),\n",
    "                                      np.rint(torch.squeeze(labels_R).detach().numpy().flatten() * max_load))\n",
    "        acc_bin.append(accuracy_bins)\n",
    "\n",
    "    mean_mae = np.mean(losses_mae)\n",
    "    mean_rmse = np.mean(losses_rmse)\n",
    "    mean_acc = np.mean(acc)\n",
    "    mean_acc_bin = np.mean(acc_bin)\n",
    "\n",
    "    print('Tested: mae_mean: {}'.format(mean_mae))\n",
    "    print('Tested: rmse_mean: {}'.format(mean_rmse))\n",
    "    print('Tested: accuracy_mean: {}'.format(mean_acc))\n",
    "    print('Tested: accuracy_bin_mean: {}'.format(mean_acc_bin))\n",
    "    return None"
   ],
   "metadata": {
    "id": "TgliCVP6tevb",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1676058137158,
     "user_tz": 300,
     "elapsed": 9,
     "user": {
      "displayName": "MOHAMED CHAABEN",
      "userId": "09788245889635529508"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TestModel(model, test_loader, max_load)"
   ],
   "metadata": {
    "id": "of4w_pCfPweH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ],
   "metadata": {
    "id": "JyoUckUtlivH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "paE19yar4ABH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def kfoldTrain(model, train_dataloader, valid_dataloader, learning_rate=1e-5, num_epochs=2, patience=10,\n",
    "               min_delta=0.00001):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "\n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "\n",
    "    dataset = train_dataloader.dataset\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(dataset)):\n",
    "        print('------------fold no---------{}-----------------'.format(fold))\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "\n",
    "        valid_subsampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=20, sampler=train_subsampler, drop_last=True)\n",
    "        validloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=20, sampler=valid_subsampler, drop_last=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            trained_number = 0\n",
    "\n",
    "            valid_dataloader_iter = iter(validloader)\n",
    "\n",
    "            losses_epoch_train = []\n",
    "            losses_epoch_valid = []\n",
    "            for data in trainloader:\n",
    "\n",
    "                inputs_R, labels_R = data[0]\n",
    "                inputs_D, labels_D = data[1]\n",
    "                inputs_W, labels_W = data[2]\n",
    "\n",
    "                inputs_R, labels_R = Variable(inputs_R), Variable(labels_R)\n",
    "                inputs_D, labels_D = Variable(inputs_D), Variable(labels_D)\n",
    "                inputs_W, labels_W = Variable(inputs_W), Variable(labels_W)\n",
    "\n",
    "                model.zero_grad()\n",
    "\n",
    "                outputs = model(inputs_R, inputs_D, inputs_W)\n",
    "\n",
    "                loss_train = loss_MSE(outputs, torch.squeeze(labels_R))\n",
    "\n",
    "                losses_train.append(loss_train.data)\n",
    "                losses_epoch_train.append(loss_train.data)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss_train.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                # validation\n",
    "                try:\n",
    "                    data_val = next(valid_dataloader_iter)\n",
    "                    inputs_val_R, labels_val_R = data_val[0]\n",
    "                    inputs_val_D, labels_val_D = data_val[1]\n",
    "                    inputs_val_W, labels_val_W = data_val[2]\n",
    "\n",
    "                except StopIteration:\n",
    "                    valid_dataloader_iter = iter(validloader)\n",
    "                    data_val = next(valid_dataloader_iter)\n",
    "\n",
    "                inputs_val_R, labels_val_R = Variable(inputs_val_R), Variable(labels_val_R)\n",
    "                inputs_val_D, labels_val_D = Variable(inputs_val_D), Variable(labels_val_D)\n",
    "                inputs_val_W, labels_val_W = Variable(inputs_val_W), Variable(labels_val_W)\n",
    "\n",
    "                outputs_val = model(inputs_val_R, inputs_val_D, inputs_val_W)\n",
    "\n",
    "                loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val_R))\n",
    "                losses_valid.append(loss_valid.data)\n",
    "                losses_epoch_valid.append(loss_valid.data)\n",
    "\n",
    "                # output\n",
    "                trained_number += 1\n",
    "\n",
    "            avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "            avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "            losses_epochs_train.append(avg_losses_epoch_train)\n",
    "            losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "\n",
    "            # Early Stopping\n",
    "            if epoch == 0:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = 10000.0\n",
    "                if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                    min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "            else:\n",
    "                if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                    is_best_model = 1\n",
    "                    best_model = model\n",
    "                    min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "                    patient_epoch = 0\n",
    "                else:\n",
    "                    is_best_model = 0\n",
    "                    patient_epoch += 1\n",
    "                    if patient_epoch >= patience:\n",
    "                        print('Early Stopped at Epoch:', epoch)\n",
    "                        break\n",
    "\n",
    "            # Print training parameters\n",
    "            cur_time = time.time()\n",
    "            print('Epoch: {}, train_loss: {}, val_loss:{} ,time: {}, best model: {}'.format(\n",
    "                epoch,\n",
    "                np.around(avg_losses_epoch_train, decimals=8),\n",
    "                np.around(avg_losses_epoch_valid, decimals=8),\n",
    "                np.around([cur_time - pre_time], decimals=2),\n",
    "                is_best_model))\n",
    "            pre_time = cur_time\n",
    "        TestModel(model, validloader, max_load)\n",
    "\n",
    "    return model, [losses_train, losses_epochs_train, losses_epoch_valid], is_best_model"
   ],
   "metadata": {
    "id": "Bz_9gk5mbdVj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kfoldTrain(model, train_loader, valid_loader)"
   ],
   "metadata": {
    "id": "AFcwQjeqnHkM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "wkerAnA3nM1m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "aCxDCbdkoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "CIPLuZNboDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "rI_JUqu8oDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "RNVmfU8voDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "ZFRC36-KoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "DK_R3aGeoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "pb2jITgyoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "oDr-fGdPoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "CxNTf0ePoDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "bDeBQneloDvP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "1IVAj-x5oDvP"
   }
  }
 ]
}
